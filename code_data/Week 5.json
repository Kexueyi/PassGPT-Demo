[
  {
    "type": "Import",
    "from": "sklearn.feature_extraction.text",
    "import": [
      {
        "name": "TfidfVectorizer",
        "alias": null
      },
      {
        "name": "CountVectorizer",
        "alias": null
      }
    ],
    "start": {
      "line": 9,
      "column": 0
    },
    "end": {
      "line": 9,
      "column": 75
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 10,
      "column": 0
    },
    "end": {
      "line": 10,
      "column": 19
    },
    "name": "pandas",
    "alias": "pd"
  },
  {
    "type": "Import",
    "start": {
      "line": 11,
      "column": 0
    },
    "end": {
      "line": 11,
      "column": 9
    },
    "name": "re",
    "alias": null
  },
  {
    "type": "Import",
    "from": "keras.preprocessing.text",
    "import": {
      "name": "text_to_word_sequence",
      "alias": null
    },
    "start": {
      "line": 12,
      "column": 0
    },
    "end": {
      "line": 12,
      "column": 58
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 13,
      "column": 0
    },
    "end": {
      "line": 13,
      "column": 11
    },
    "name": "nltk",
    "alias": null
  },
  {
    "type": "Import",
    "from": "nltk.corpus",
    "import": {
      "name": "stopwords",
      "alias": null
    },
    "start": {
      "line": 14,
      "column": 0
    },
    "end": {
      "line": 14,
      "column": 33
    }
  },
  {
    "type": "Import",
    "from": "nltk.tokenize",
    "import": {
      "name": "word_tokenize",
      "alias": null
    },
    "start": {
      "line": 15,
      "column": 0
    },
    "end": {
      "line": 15,
      "column": 39
    }
  },
  {
    "type": "Import",
    "from": "sklearn.feature_extraction.text",
    "import": {
      "name": "TfidfVectorizer",
      "alias": null
    },
    "start": {
      "line": 16,
      "column": 0
    },
    "end": {
      "line": 16,
      "column": 59
    }
  },
  {
    "type": "Import",
    "from": "sklearn.model_selection",
    "import": {
      "name": "cross_validate",
      "alias": null
    },
    "start": {
      "line": 17,
      "column": 0
    },
    "end": {
      "line": 17,
      "column": 50
    }
  },
  {
    "type": "Import",
    "from": "sklearn.svm",
    "import": {
      "name": "SVC",
      "alias": null
    },
    "start": {
      "line": 18,
      "column": 0
    },
    "end": {
      "line": 18,
      "column": 27
    }
  },
  {
    "type": "Import",
    "from": "sklearn.metrics",
    "import": {
      "name": "accuracy_score",
      "alias": null
    },
    "start": {
      "line": 19,
      "column": 0
    },
    "end": {
      "line": 19,
      "column": 42
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 20,
      "column": 0
    },
    "end": {
      "line": 20,
      "column": 18
    },
    "name": "numpy",
    "alias": "np"
  },
  {
    "type": "Assignment",
    "body": "imdb_df=pd.read_csv(r\"C:\\Users\\liuru\\Desktop\\EE6405\\Data\\IMDB\\IMDB Dataset.csv\")",
    "start": {
      "line": 28,
      "column": 0
    },
    "end": {
      "line": 28,
      "column": 82
    }
  },
  {
    "type": "Assignment",
    "body": "df_positive=imdb_df[imdb_df['sentiment']=='positive'][:5000]",
    "start": {
      "line": 29,
      "column": 0
    },
    "end": {
      "line": 29,
      "column": 62
    }
  },
  {
    "type": "Assignment",
    "body": "df_negative=imdb_df[imdb_df['sentiment']=='negative'][:5000]",
    "start": {
      "line": 30,
      "column": 0
    },
    "end": {
      "line": 30,
      "column": 62
    }
  },
  {
    "type": "Assignment",
    "body": "imdb=pd.concat([df_positive,df_negative])",
    "start": {
      "line": 31,
      "column": 0
    },
    "end": {
      "line": 31,
      "column": 44
    }
  },
  null,
  {
    "type": "Assignment",
    "body": "imdb['review']=imdb['review'].apply(lambdax:re.sub('(<.*?>)',' ',x))",
    "start": {
      "line": 39,
      "column": 0
    },
    "end": {
      "line": 39,
      "column": 74
    }
  },
  {
    "type": "Assignment",
    "body": "imdb['review']=imdb['review'].apply(lambdax:re.sub('[,\\.!?:()\"]','',x))",
    "start": {
      "line": 41,
      "column": 0
    },
    "end": {
      "line": 41,
      "column": 77
    }
  },
  {
    "type": "Assignment",
    "body": "imdb['review']=imdb['review'].apply(lambdax:x.strip())",
    "start": {
      "line": 43,
      "column": 0
    },
    "end": {
      "line": 43,
      "column": 58
    }
  },
  {
    "type": "Assignment",
    "body": "imdb['review']=imdb['review'].apply(lambdax:re.sub('[^a-zA-Z\"]',' ',x))",
    "start": {
      "line": 45,
      "column": 0
    },
    "end": {
      "line": 45,
      "column": 75
    }
  },
  {
    "type": "Assignment",
    "body": "imdb['review']=imdb['review'].apply(lambdax:x.lower())",
    "start": {
      "line": 47,
      "column": 0
    },
    "end": {
      "line": 47,
      "column": 58
    }
  },
  {
    "type": "Function call",
    "name": "nltk.download",
    "arguments": "('wordnet')",
    "start": {
      "line": 53,
      "column": 0
    },
    "end": {
      "line": 53,
      "column": 24
    }
  },
  {
    "type": "Import",
    "from": "nltk.stem",
    "import": {
      "name": "WordNetLemmatizer",
      "alias": null
    },
    "start": {
      "line": 54,
      "column": 0
    },
    "end": {
      "line": 54,
      "column": 39
    }
  },
  {
    "type": "Import",
    "from": "nltk.tokenize",
    "import": {
      "name": "word_tokenize",
      "alias": null
    },
    "start": {
      "line": 55,
      "column": 0
    },
    "end": {
      "line": 55,
      "column": 39
    }
  },
  {
    "type": "Function call",
    "name": "nltk.download",
    "arguments": "('averaged_perceptron_tagger')",
    "start": {
      "line": 56,
      "column": 0
    },
    "end": {
      "line": 56,
      "column": 43
    }
  },
  {
    "type": "Assignment",
    "body": "lemmatizer=WordNetLemmatizer()",
    "start": {
      "line": 57,
      "column": 0
    },
    "end": {
      "line": 57,
      "column": 31
    }
  },
  {
    "type": "Import",
    "from": "nltk.corpus",
    "import": {
      "name": "wordnet",
      "alias": null
    },
    "start": {
      "line": 58,
      "column": 0
    },
    "end": {
      "line": 58,
      "column": 31
    }
  },
  {
    "type": "Function declaration",
    "body": "defpos_tagger(nltk_tag):     ifnltk_tag.startswith('J'):         returnwordnet.ADJ  elifnltk_tag.startswith('V'):         returnwordnet.VERB  elifnltk_tag.startswith('N'):         returnwordnet.NOUN  elifnltk_tag.startswith('R'):         returnwordnet.ADV  else:         returnNone\n\n\n",
    "start": {
      "line": 64,
      "column": 0
    },
    "end": {
      "line": 75,
      "column": 1
    }
  },
  {
    "type": "Function declaration",
    "body": "deftagged_lemma(string):     pos_tagged=nltk.pos_tag(nltk.word_tokenize(string)) wordnet_tagged=list(map(lambdax:(x[0],pos_tagger(x[1])),pos_tagged)) lemmatized_sentence=[] forword,taginwordnet_tagged:         iftagisNone:             lemmatized_sentence.append(word)  else:             lemmatized_sentence.append(lemmatizer.lemmatize(word,tag))   lemmatized_sentence=\" \".join(lemmatized_sentence) returnlemmatized_sentence\n\n",
    "start": {
      "line": 75,
      "column": 0
    },
    "end": {
      "line": 95,
      "column": 1
    }
  },
  {
    "type": "Assignment",
    "body": "imdb['review']=imdb['review'].apply(tagged_lemma)",
    "start": {
      "line": 95,
      "column": 0
    },
    "end": {
      "line": 95,
      "column": 49
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "(imdb['review'][3])",
    "start": {
      "line": 96,
      "column": 0
    },
    "end": {
      "line": 96,
      "column": 24
    }
  },
  {
    "type": "Assignment",
    "body": "words=imdb['review'].apply(lambdax:text_to_word_sequence(x))",
    "start": {
      "line": 102,
      "column": 0
    },
    "end": {
      "line": 102,
      "column": 64
    }
  },
  {
    "type": "Assignment",
    "body": "stop_words=set(stopwords.words('english'))",
    "start": {
      "line": 103,
      "column": 0
    },
    "end": {
      "line": 103,
      "column": 44
    }
  },
  {
    "type": "Assignment",
    "body": "filtered_words=words.apply(lambdax:[wforwinxifnotwinstop_words])",
    "start": {
      "line": 104,
      "column": 0
    },
    "end": {
      "line": 104,
      "column": 77
    }
  },
  {
    "type": "Assignment",
    "body": "imdb['review']=filtered_words.apply(lambdax:\" \".join(x))",
    "start": {
      "line": 105,
      "column": 0
    },
    "end": {
      "line": 105,
      "column": 60
    }
  },
  null,
  {
    "type": "Assignment",
    "body": "imdb.sentiment=imdb.sentiment.apply(lambdax:1ifx=='positive'else0)",
    "start": {
      "line": 112,
      "column": 0
    },
    "end": {
      "line": 112,
      "column": 74
    }
  },
  {
    "type": "Import",
    "from": "sklearn.model_selection",
    "import": {
      "name": "train_test_split",
      "alias": null
    },
    "start": {
      "line": 118,
      "column": 0
    },
    "end": {
      "line": 118,
      "column": 52
    }
  },
  {
    "type": "Assignment",
    "body": "train_review,test_review,train_sent,test_sent=train_test_split(imdb['review'],imdb['sentiment'],test_size=0.25,random_state=42)",
    "start": {
      "line": 119,
      "column": 0
    },
    "end": {
      "line": 119,
      "column": 135
    }
  },
  {
    "type": "Assignment",
    "body": "tv=TfidfVectorizer(stop_words='english')",
    "start": {
      "line": 126,
      "column": 0
    },
    "end": {
      "line": 126,
      "column": 40
    }
  },
  {
    "type": "Assignment",
    "body": "train_review_tfidf=np.asarray(tv.fit_transform(train_review).todense())",
    "start": {
      "line": 128,
      "column": 0
    },
    "end": {
      "line": 128,
      "column": 71
    }
  },
  {
    "type": "Assignment",
    "body": "test_review_tfidf=np.asarray(tv.transform(test_review).todense())",
    "start": {
      "line": 130,
      "column": 0
    },
    "end": {
      "line": 130,
      "column": 65
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "('Tfidf_train:',train_review_tfidf.shape)",
    "start": {
      "line": 131,
      "column": 0
    },
    "end": {
      "line": 131,
      "column": 46
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "('Tfidf_test:',test_review_tfidf.shape)",
    "start": {
      "line": 132,
      "column": 0
    },
    "end": {
      "line": 132,
      "column": 44
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "(train_review_tfidf[3].shape)",
    "start": {
      "line": 138,
      "column": 0
    },
    "end": {
      "line": 138,
      "column": 34
    }
  },
  {
    "type": "Import",
    "from": "sklearn.metrics",
    "import": [
      {
        "name": "accuracy_score",
        "alias": null
      },
      {
        "name": "precision_score",
        "alias": null
      },
      {
        "name": "recall_score",
        "alias": null
      },
      {
        "name": "confusion_matrix",
        "alias": null
      }
    ],
    "start": {
      "line": 146,
      "column": 0
    },
    "end": {
      "line": 146,
      "column": 91
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 147,
      "column": 0
    },
    "end": {
      "line": 147,
      "column": 21
    },
    "name": "seaborn",
    "alias": "sns"
  },
  {
    "type": "Function declaration",
    "body": "defgetConfMatrix(pred_data,actual):     conf_mat=confusion_matrix(actual,pred_data,labels=[0,1]) accuracy=accuracy_score(actual,pred_data) precision=precision_score(actual,pred_data,average='micro') recall=recall_score(actual,pred_data,average='micro') sns.heatmap(conf_mat,annot=True,fmt=\".0f\",annot_kws={\"size\":18}) print('Accuracy: '+str(accuracy)) print('Precision: '+str(precision)) print('Recall: '+str(recall))\n\n",
    "start": {
      "line": 149,
      "column": 0
    },
    "end": {
      "line": 163,
      "column": 1
    }
  },
  {
    "type": "Import",
    "from": "sklearn",
    "import": {
      "name": "svm",
      "alias": null
    },
    "start": {
      "line": 163,
      "column": 0
    },
    "end": {
      "line": 163,
      "column": 23
    }
  },
  {
    "type": "Assignment",
    "body": "clf=svm.SVC(kernel='rbf')",
    "start": {
      "line": 166,
      "column": 0
    },
    "end": {
      "line": 166,
      "column": 27
    }
  },
  {
    "type": "Function call",
    "name": "clf.fit",
    "arguments": "(train_review_tfidf,train_sent)",
    "start": {
      "line": 169,
      "column": 0
    },
    "end": {
      "line": 169,
      "column": 39
    }
  },
  {
    "type": "Assignment",
    "body": "y_pred=clf.predict(test_review_tfidf)",
    "start": {
      "line": 172,
      "column": 0
    },
    "end": {
      "line": 172,
      "column": 39
    }
  },
  {
    "type": "Function call",
    "name": "getConfMatrix",
    "arguments": "(y_pred,test_sent)",
    "start": {
      "line": 180,
      "column": 0
    },
    "end": {
      "line": 180,
      "column": 31
    }
  },
  {
    "type": "Import",
    "from": "sklearn.metrics",
    "import": {
      "name": "f1_score",
      "alias": null
    },
    "start": {
      "line": 186,
      "column": 0
    },
    "end": {
      "line": 186,
      "column": 36
    }
  },
  {
    "type": "Assignment",
    "body": "micro=f1_score(test_sent,y_pred,average='micro')",
    "start": {
      "line": 187,
      "column": 0
    },
    "end": {
      "line": 187,
      "column": 52
    }
  },
  {
    "type": "Assignment",
    "body": "macro=f1_score(test_sent,y_pred,average='macro')",
    "start": {
      "line": 188,
      "column": 0
    },
    "end": {
      "line": 188,
      "column": 51
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "('F1 Micro: '+str(micro))",
    "start": {
      "line": 189,
      "column": 0
    },
    "end": {
      "line": 189,
      "column": 31
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "('F1 Macro: '+str(macro))",
    "start": {
      "line": 190,
      "column": 0
    },
    "end": {
      "line": 190,
      "column": 31
    }
  },
  {
    "type": "Import",
    "from": "sklearn.linear_model",
    "import": {
      "name": "LogisticRegression",
      "alias": null
    },
    "start": {
      "line": 200,
      "column": 0
    },
    "end": {
      "line": 200,
      "column": 51
    }
  },
  {
    "type": "Import",
    "from": "sklearn",
    "import": {
      "name": "metrics",
      "alias": null
    },
    "start": {
      "line": 201,
      "column": 0
    },
    "end": {
      "line": 201,
      "column": 27
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 202,
      "column": 0
    },
    "end": {
      "line": 202,
      "column": 31
    },
    "name": "matplotlib.pyplot",
    "alias": "plt"
  },
  {
    "type": "Assignment",
    "body": "log_regression=LogisticRegression()",
    "start": {
      "line": 204,
      "column": 0
    },
    "end": {
      "line": 204,
      "column": 37
    }
  },
  {
    "type": "Function call",
    "name": "log_regression.fit",
    "arguments": "(train_review_tfidf,train_sent)",
    "start": {
      "line": 207,
      "column": 0
    },
    "end": {
      "line": 207,
      "column": 50
    }
  },
  {
    "type": "Assignment",
    "body": "y_pred_proba=log_regression.predict_proba(test_review_tfidf)[::,1]",
    "start": {
      "line": 214,
      "column": 0
    },
    "end": {
      "line": 214,
      "column": 68
    }
  },
  {
    "type": "Assignment",
    "body": "fpr,tpr,_=metrics.roc_curve(test_sent,y_pred_proba)",
    "start": {
      "line": 215,
      "column": 0
    },
    "end": {
      "line": 215,
      "column": 57
    }
  },
  {
    "type": "Assignment",
    "body": "auc=metrics.roc_auc_score(test_sent,y_pred_proba)",
    "start": {
      "line": 216,
      "column": 0
    },
    "end": {
      "line": 216,
      "column": 52
    }
  },
  {
    "type": "Function call",
    "name": "plt.plot",
    "arguments": "(fpr,tpr,label=\"AUC=\"+str(auc))",
    "start": {
      "line": 219,
      "column": 0
    },
    "end": {
      "line": 219,
      "column": 39
    }
  },
  {
    "type": "Function call",
    "name": "plt.ylabel",
    "arguments": "('True Positive Rate')",
    "start": {
      "line": 220,
      "column": 0
    },
    "end": {
      "line": 220,
      "column": 32
    }
  },
  {
    "type": "Function call",
    "name": "plt.xlabel",
    "arguments": "('False Positive Rate')",
    "start": {
      "line": 221,
      "column": 0
    },
    "end": {
      "line": 221,
      "column": 33
    }
  },
  {
    "type": "Function call",
    "name": "plt.legend",
    "arguments": "(loc=4)",
    "start": {
      "line": 222,
      "column": 0
    },
    "end": {
      "line": 222,
      "column": 17
    }
  },
  {
    "type": "Function call",
    "name": "plt.show",
    "arguments": "()",
    "start": {
      "line": 223,
      "column": 0
    },
    "end": {
      "line": 223,
      "column": 10
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 231,
      "column": 0
    },
    "end": {
      "line": 231,
      "column": 11
    },
    "name": "nltk",
    "alias": null
  },
  {
    "type": "Import",
    "from": "nltk",
    "import": {
      "name": "word_tokenize",
      "alias": null
    },
    "start": {
      "line": 232,
      "column": 0
    },
    "end": {
      "line": 232,
      "column": 30
    }
  },
  {
    "type": "Import",
    "from": "nltk.translate.bleu_score",
    "import": {
      "name": "SmoothingFunction",
      "alias": null
    },
    "start": {
      "line": 233,
      "column": 0
    },
    "end": {
      "line": 233,
      "column": 55
    }
  },
  {
    "type": "Assignment",
    "body": "ref='The guard arrived late because it was raining.'",
    "start": {
      "line": 234,
      "column": 0
    },
    "end": {
      "line": 234,
      "column": 54
    }
  },
  {
    "type": "Assignment",
    "body": "cand='The guard arrived late because of the rain.'",
    "start": {
      "line": 235,
      "column": 0
    },
    "end": {
      "line": 235,
      "column": 52
    }
  },
  {
    "type": "Assignment",
    "body": "smoothie=SmoothingFunction().method1",
    "start": {
      "line": 236,
      "column": 0
    },
    "end": {
      "line": 236,
      "column": 38
    }
  },
  {
    "type": "Assignment",
    "body": "reference=word_tokenize(ref)",
    "start": {
      "line": 237,
      "column": 0
    },
    "end": {
      "line": 237,
      "column": 30
    }
  },
  {
    "type": "Assignment",
    "body": "candidate=word_tokenize(cand)",
    "start": {
      "line": 238,
      "column": 0
    },
    "end": {
      "line": 238,
      "column": 31
    }
  },
  {
    "type": "Assignment",
    "body": "weights=(0.25,0.25,0.25,0.25)",
    "start": {
      "line": 239,
      "column": 0
    },
    "end": {
      "line": 239,
      "column": 34
    }
  },
  {
    "type": "Assignment",
    "body": "BLEUscore=nltk.translate.bleu_score.sentence_bleu([reference],candidate,weights,smoothing_function=smoothie)",
    "start": {
      "line": 240,
      "column": 0
    },
    "end": {
      "line": 240,
      "column": 113
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "(BLEUscore)",
    "start": {
      "line": 241,
      "column": 0
    },
    "end": {
      "line": 241,
      "column": 16
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 249,
      "column": 0
    },
    "end": {
      "line": 249,
      "column": 15
    },
    "name": "evaluate",
    "alias": null
  },
  {
    "type": "Assignment",
    "body": "rouge=evaluate.load('rouge')",
    "start": {
      "line": 250,
      "column": 0
    },
    "end": {
      "line": 250,
      "column": 30
    }
  },
  {
    "type": "Assignment",
    "body": "predictions=[\"Transformers Transformers are fast plus efficient\",\"Good Morning\",\"I am waiting for new Transformers\"]",
    "start": {
      "line": 251,
      "column": 0
    },
    "end": {
      "line": 252,
      "column": 67
    }
  },
  {
    "type": "Assignment",
    "body": "references=[[\"HuggingFace Transformers are fast efficient plus awesome\",\"Transformers are awesome because they are fast to execute\"],[\"Good Morning Transformers\",\"Morning Transformers\"],[\"People are eagerly waiting for new Transformer models\",\"People are very excited about new Transformers\"]]",
    "start": {
      "line": 253,
      "column": 0
    },
    "end": {
      "line": 260,
      "column": 1
    }
  },
  {
    "type": "Assignment",
    "body": "results=rouge.compute(predictions=predictions,references=references)",
    "start": {
      "line": 261,
      "column": 0
    },
    "end": {
      "line": 261,
      "column": 71
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "(results)",
    "start": {
      "line": 262,
      "column": 0
    },
    "end": {
      "line": 262,
      "column": 14
    }
  },
  {
    "type": "Import",
    "from": "nltk.translate",
    "import": {
      "name": "meteor",
      "alias": null
    },
    "start": {
      "line": 270,
      "column": 0
    },
    "end": {
      "line": 270,
      "column": 33
    }
  },
  {
    "type": "Import",
    "from": "nltk",
    "import": {
      "name": "word_tokenize",
      "alias": null
    },
    "start": {
      "line": 271,
      "column": 0
    },
    "end": {
      "line": 271,
      "column": 30
    }
  },
  {
    "type": "Assignment",
    "body": "score=round(meteor([word_tokenize('The cat sat on the mat')],word_tokenize('The cat was sat on the mat')),4)",
    "start": {
      "line": 272,
      "column": 0
    },
    "end": {
      "line": 273,
      "column": 67
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "('The METEOR score is: '+str(score))",
    "start": {
      "line": 274,
      "column": 0
    },
    "end": {
      "line": 274,
      "column": 41
    }
  },
  {
    "type": "Import",
    "from": "gensim.models",
    "import": {
      "name": "Word2Vec",
      "alias": null
    },
    "start": {
      "line": 280,
      "column": 0
    },
    "end": {
      "line": 280,
      "column": 34
    }
  },
  {
    "type": "Import",
    "from": "nltk.tokenize",
    "import": {
      "name": "word_tokenize",
      "alias": null
    },
    "start": {
      "line": 281,
      "column": 0
    },
    "end": {
      "line": 281,
      "column": 39
    }
  },
  {
    "type": "Assignment",
    "body": "sentences=[\"Word2Vec is a technique for word embedding.\",\"Embedding words in vector space is powerful for NLP.\",\"Gensim provides an easy way to work with Word2Vec.\",]",
    "start": {
      "line": 284,
      "column": 0
    },
    "end": {
      "line": 288,
      "column": 1
    }
  },
  {
    "type": "Assignment",
    "body": "tokenized_sentences=[word_tokenize(sentence.lower())forsentenceinsentences]",
    "start": {
      "line": 291,
      "column": 0
    },
    "end": {
      "line": 291,
      "column": 81
    }
  },
  {
    "type": "Assignment",
    "body": "model=Word2Vec(tokenized_sentences,vector_size=100,window=5,min_count=1,sg=0)",
    "start": {
      "line": 294,
      "column": 0
    },
    "end": {
      "line": 294,
      "column": 83
    }
  },
  {
    "type": "Function call",
    "name": "model.save",
    "arguments": "(\"word2vec.model\")",
    "start": {
      "line": 298,
      "column": 0
    },
    "end": {
      "line": 298,
      "column": 28
    }
  },
  {
    "type": "Assignment",
    "body": "word=\"word\"",
    "start": {
      "line": 304,
      "column": 0
    },
    "end": {
      "line": 304,
      "column": 13
    }
  },
  {
    "type": "If Statement",
    "body": "ifwordinmodel.wv:     embedding=model.wv[word] print(f\"Embedding for '{word}': {embedding}\")\n\nelse:     print(f\"'{word}' is not in the vocabulary.\")\n\n",
    "start": {
      "line": 305,
      "column": 0
    },
    "end": {
      "line": 312,
      "column": 1
    }
  },
  {
    "type": "Assignment",
    "body": "similarity=model.wv.similarity(\"word\",\"embedding\")",
    "start": {
      "line": 312,
      "column": 0
    },
    "end": {
      "line": 312,
      "column": 53
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "(f\"Similarity between 'word' and 'embedding': {similarity}\")",
    "start": {
      "line": 313,
      "column": 0
    },
    "end": {
      "line": 313,
      "column": 65
    }
  },
  {
    "type": "Import",
    "start": {
      "line": 321,
      "column": 0
    },
    "end": {
      "line": 321,
      "column": 31
    },
    "name": "gensim.downloader",
    "alias": "api"
  },
  {
    "type": "Assignment",
    "body": "glove_model=api.load(\"glove-wiki-gigaword-100\")",
    "start": {
      "line": 324,
      "column": 0
    },
    "end": {
      "line": 324,
      "column": 49
    }
  },
  {
    "type": "Assignment",
    "body": "word=\"nero\"",
    "start": {
      "line": 327,
      "column": 0
    },
    "end": {
      "line": 327,
      "column": 13
    }
  },
  {
    "type": "Try Statement",
    "body": "try:     embedding=glove_model[word] print(f\"Embedding for '{word}':\") print(embedding)\n\nexceptKeyError:     print(f\"'{word}' is not in the vocabulary.\")\n\n",
    "start": {
      "line": 328,
      "column": 0
    },
    "end": {
      "line": 336,
      "column": 1
    }
  },
  {
    "type": "Assignment",
    "body": "similar_words=glove_model.most_similar(word)",
    "start": {
      "line": 336,
      "column": 0
    },
    "end": {
      "line": 336,
      "column": 46
    }
  },
  {
    "type": "Function call",
    "name": "print",
    "arguments": "(f\"\\nWords most similar to '{word}':\")",
    "start": {
      "line": 337,
      "column": 0
    },
    "end": {
      "line": 337,
      "column": 43
    }
  },
  {
    "type": "For Loop Statement",
    "body": "forsimilar_word,scoreinsimilar_words:     print(similar_word,score)\n\n",
    "start": {
      "line": 338,
      "column": 0
    },
    "end": {
      "line": 346,
      "column": 1
    }
  }
]