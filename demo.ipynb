{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PassGPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cousre Infomation Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In week 3 of the course, the topics covered are Term Weighting Scheme and Topic Modelling. \n",
      "\n",
      "1. Term Weighting Scheme: This topic focuses on different techniques used to assign weights to terms in a document or a corpus. Common term weighting schemes include TF-IDF (Term Frequency-Inverse Document Frequency), BM25 (Best Matching 25), and others. Understanding term weighting schemes is essential in Information Retrieval and Text Mining tasks to identify the importance of terms in a document or a collection of documents.\n",
      "\n",
      "2. Topic Modelling: Topic Modelling is a statistical modeling technique for discovering abstract topics within a collection of documents. Popular algorithms for topic modeling include Latent Dirichlet Allocation (LDA) and Non-negative Matrix Factorization (NMF). Topic modeling helps in uncovering the underlying themes or topics present in a large corpus of text data, which can be useful for tasks like document categorization, information retrieval, and sentiment analysis.\n",
      "\n",
      "Additionally, the week may also cover Dimensionality Reduction techniques like Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) to reduce the complexity of text data while preserving important information. These techniques are essential for handling high-dimensional text data efficiently in Natural Language Processing tasks.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize the OpenAI client, replacing \"sk-...\" with your key\n",
    "client = OpenAI(api_key=\"sk-...\")\n",
    "\n",
    "\n",
    "def load_course_info(file_path):\n",
    "    \"\"\"\n",
    "    Loads the course information from a JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        course_info = json.load(file)\n",
    "    return course_info\n",
    "\n",
    "def format_course_info_for_gpt(course_info):\n",
    "    \"\"\"\n",
    "    Formats the course information into a text summary that GPT can understand.\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    for course, details in course_info.items():\n",
    "        concepts = ', '.join([concept['name'] for concept in details['Concepts']])\n",
    "        summary = f\"{details['Teaching Week']}: {details['Title']} covers {concepts}.\"\n",
    "        summaries.append(summary)\n",
    "    return \" \".join(summaries)\n",
    "\n",
    "def query_gpt_with_course_info(query, course_info_summary):\n",
    "    \"\"\"\n",
    "    Submits a query along with the formatted course information to GPT for processing,\n",
    "    using the newer client.chat.completions.create interface.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{course_info_summary} Your task is to provide a comprehensive response based on the information provided.\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust the model as needed\n",
    "            messages=messages,\n",
    "        )\n",
    "        # Assuming we need to get the last message from the chat completion properly\n",
    "        # Adjusting for the correct way to access the last message's content\n",
    "        if chat_completion.choices and len(chat_completion.choices) > 0:\n",
    "            last_message = chat_completion.choices[0].message.content.strip()\n",
    "            return last_message\n",
    "        else:\n",
    "            return \"No response was returned by GPT.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error querying GPT with course info: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = \"./data/info.json\"\n",
    "course_info = load_course_info(file_path)\n",
    "course_info_summary = format_course_info_for_gpt(course_info)\n",
    "\n",
    "# Replace this query with the user's actual question\n",
    "query = \"What is discussed in week 3?\"\n",
    "response = query_gpt_with_course_info(query, course_info_summary)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of reviewing course EE6405 would depend on the individual's study habits, prior knowledge, and the amount of time dedicated to studying. Typically, a comprehensive review of a course like EE6405, which covers Term Weighting Schemes, Topic Modeling, Dimensionality Reduction, Evaluation Metrics, Word Embeddings, Seq2Seq Models, Attention Mechanism, Transformer Models, Transformer Based Large Language Models, NLP Applications Across Diverse Industries, and Deep-dive into NLP, could take several weeks to months to fully grasp the material and be able to apply it effectively. It is recommended to allocate sufficient time for each topic, practice with exercises, and engage in hands-on projects to reinforce learning. Additionally, seeking clarification from instructors or peers and actively participating in discussions can also enhance understanding.\n"
     ]
    }
   ],
   "source": [
    "query = \"How long will it takes for course EE6405 reviewing?\"\n",
    "response = query_gpt_with_course_info(query, course_info_summary)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Dirichlet Allocation (LDA) is a topic modeling technique used to classify text in a document to a particular topic. LDA assumes that each document is a mixture of a small number of topics and that each word's presence in a document is attributable to one of the document's topics.\n",
      "\n",
      "In the course on Natural Language Processing, LDA is typically introduced in Week 3 as part of the module on Topic Modeling. The specific page number where LDA is covered may vary depending on the course materials used, but it is generally discussed in the context of term weighting schemes and topic modeling techniques.\n",
      "\n",
      "If you are following a specific course or textbook, please refer to the relevant section on Topic Modeling in Week 3 to find detailed information about Latent Dirichlet Allocation (LDA) and its application in NLP.\n"
     ]
    }
   ],
   "source": [
    "query = \"Please answer what is LDA, when this concept was taught, which page, which week?\"\n",
    "response = query_gpt_with_course_info(query, course_info_summary)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
